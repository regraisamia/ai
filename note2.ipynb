{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import networkx as nx\n",
    "from pathlib import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Dialogue  Emotion  Act  Topic\n",
      "0                               The kitchen stinks .        2    3      1\n",
      "1               I'll throw out the garbage . __eou__        0    4      1\n",
      "2  So Dick , how about getting some coffee for to...        4    3      1\n",
      "3  Coffee ? I don ’ t honestly like that kind of ...        2    4      1\n",
      "4  Come on , you can at least try a little , besi...        0    3      1\n"
     ]
    }
   ],
   "source": [
    "# Chargement des fichiers\n",
    "data_dir = \"C:/Users/hp/Desktop/ai/EMNLP_dataset\"\n",
    "\n",
    "with open(os.path.join(data_dir, \"dialogues_text.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    dialogues = [line.strip().split(\" __eou__ \") for line in f]\n",
    "\n",
    "with open(os.path.join(data_dir, \"dialogues_emotion.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    emotions = [list(map(int, line.strip().split())) for line in f]\n",
    "\n",
    "with open(os.path.join(data_dir, \"dialogues_act.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    acts = [list(map(int, line.strip().split())) for line in f]\n",
    "\n",
    "with open(os.path.join(data_dir, \"dialogues_topic.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    topics = [int(line.strip()) for line in f]\n",
    "\n",
    "# Vérification des dimensions\n",
    "assert len(dialogues) == len(emotions) == len(acts) == len(topics), \"Les fichiers n'ont pas le même nombre de lignes !\"\n",
    "\n",
    "# Filtrer les cas où les longueurs des dialogues et des émotions ne correspondent pas\n",
    "data = []\n",
    "for conv, emotion_list, act_list, topic in zip(dialogues, emotions, acts, topics):\n",
    "    if len(conv) == len(emotion_list) == len(act_list):\n",
    "        for i in range(len(conv)):\n",
    "            data.append({\n",
    "                \"Dialogue\": conv[i],\n",
    "                \"Emotion\": emotion_list[i],\n",
    "                \"Act\": act_list[i],\n",
    "                \"Topic\": topic\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
